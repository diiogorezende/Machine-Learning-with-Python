{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyObFXKAdeivCattaD3xBg5F"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# __Validação Cruzada K-Fold__\n","No caso da validação cruzada K-Fold, são criados K-Folds contendo os dados para treino e para teste em cada um desses folds. Vamos a um exemplo:\n","\n","Vamos supor que definimos um K-Fold (n_splits) de 5. Nesse caso, teríamos 5 rodadas de treinamento, e cada um desses treinamentos teria mais 5 pastas, 1 para teste e 4 para treino.\n","\n","Ao final da execução, serão gerados coeficientes de determinação R2 para cada uma das rodadas de treinamento e, após isso, tiramos a média dos 5 resultados de R2 para verificar o resultado geral. Ou seja, usando como exemplo a imagem abaixo, na iteração 1 teremos um valor de coeficiente de determinação R2, na iteração 2 teremos outro, e assim por diante. Então será calculada a média dessas pastas, que será o resultado final.\n","\n","Usamos a **K-Fold** principalmente em situações onde queremos avaliar o desempenho dos modelos de machine learning de uma forma mais robusta e evitar problemas de overfitting ou underfitting. É recomendado usar ela em cenários de datasets limitados, onde e divisão de treino e teste pode resultar em uma avaliação pouco confiável, ou quando precisamos validar nossos modelos de forma mais estável.\n","\n","**Vantagens:**\n","- Todos os dados são utilizados tanto para treino quanto para teste, o que é útil para pequenos datasets.\n","- O modelo é avaliado em vários subconjuntos, fazendo com que seja mais confiável.\n","- Pode avaliar o modelo em subconjuntos, a média das performances dá uma avaliação estável.\n","- Evita problemas de overfitting.\n","\n","**Desvantagens:**\n","- Tem maior custo computacional\n","- Não é útil para modelos sensíveis a tempo ou sequência, pois ela não considera a ordem dos dados, então, para dados sequencias ou séries temporais, ela não é muito boa.\n","- Não é muito eficiente em datasets muito desbalanceados.\n","\n","![texto](https://miro.medium.com/v2/resize:fit:800/1*kkMtezwv8qj1t9uG4nw_8g.png)\n","\n","# Validação Cruzada StratifiedKFold\n","Da mesma forma como a KFold, ela também irá gerar K pastas com quantidades iguais de dados e, em cada rodada de treinamento, usará 1 pasta como teste e as demais para treino. Ou seja, ela faz basicamente tudo igual à KFold.\n","\n","A única diferenteça está na separação das classes que a StratifiedKFold realiza. Em problemas de classificação onde temos dados **desbalanceados**, pois ela mantém a mesma proporção dos dados para cada pasta. Ou seja, ao invés de apenas criar K pastas, ela cria as K-Pastas de forma que a proporção das classes seja mantida em cada pasta.\n","\n","Usamos a **Stratified K-Fold** quando trabalhamos com dados desbalanceados, ou quando precisamos manter a distribuição das classes preservada em cada divisão de treino e teste.\n","\n","**Vantagens:**\n","- Garante que cada paste tenha aproximadamente a mesma proporção de classes do conjunto de dados original, fornecendo uma avaliação mais realista.\n","- Proporciona menos variabilidade entre as avaliações dos Folds, pois as distribuições de classes são mais consistentes.\n","\n","**Desvantagens:**\n","- Custo computacional alto\n","- Para problemas de regressão, a estratificação não faz sentido, pois os valores-alvo são contínuos.\n","- É mais complexa."],"metadata":{"id":"MzzBT_jYp8PD"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"qEs2s_Z7p5KO"},"outputs":[],"source":[]}]}