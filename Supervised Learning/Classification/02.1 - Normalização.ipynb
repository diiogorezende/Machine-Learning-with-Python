{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMJnl4LWnMT+v1j8p72+bTK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# MinMaxScaler (normalizacao)\n","É uma função que **normaliza** os dados entre um intervalo estipulado, por exemplo, 0 e 1.\n","\n","$$\n","X' = \\frac{X - X_{\\text{min}}}{X_{\\text{max}} - X_{\\text{min}}}\n","$$\n","\n","É adequado quando sabemos que os dados possuem limites conhecidos e é importante manter a distribuição original dos dados, mas escalada. É muito usado em redes neurais, que se dão bem com entradas entre 0 e 1.\n","\n","**Vantagens:**\n","- Mantém a distribuição original dos dados.\n","- Simples de entender e implementar.\n","\n","**Desvantagens:**\n","- Sensível a outliers, já que os valores mínimos e máximos podem ser distorcidos.\n","- Pode haver perda de informação.\n","\n","**Casos de uso:**\n","- Redes Neurais\n","- Métodos baseados em distância\n","- Algoritmos de otimização com restrição de intervalo\n","\n","# StandardScaler (padronizacao)\n","Transforma os dados para que tenham uma média de zero e desvio padrão de 1.\n","\n","$$\n","X' = \\frac{X - \\mu}{\\sigma}\n","$$\n","\n","Onde X é o valor original, \"u\" é a média e sigma é o desvio padrão.\n","\n","**Vantagens:**\n","- Remove a influência de diferentes escalas nos dados\n","- Útil para algoritmos que dependem de **padronizacao** dos dados.\n","\n","**Desvantagens:**\n","- É sensível a outliers, já que usa média e desvio padrão.\n","\n","**Casos de uso:**\n","- Modelos lineares (Reg Linear, SMV, etc)\n","- Redução de dimensionalidade (PCA)\n","\n","# MaxAbsScaler (normalizacao)\n","Normaliza os dados dividindo cada elemento pelo valor absoluto máximo de cada característica. Utilizamos quando possuímos dados que contém valores negativos e positivos e precisam ser normalizados, mas sem alterar a centralidade dos dados.\n","\n","$$\n","X' = \\frac{X}{\\lvert X_{\\text{max}}\\rvert}\n","$$\n","\n","**Vantagens:**\n","- Não desloca os dados, preservando os valores negativos e a centralidade\n","- Funciona com dados esparsos\n","\n","**Desvantagens:**\n","- É sensível a outliers.\n","\n","**Casos de uso:**\n","- Dados esparsos\n","- Modelos que aceitam valores negativos\n","\n","# Função Normalize (normalizacao)\n","Ajusta cada amostra de forma que o vetor de características possua norma 1.\n","Realiza a normalização de **cada linha** da matriz. Podemos ajustar 3 parâmetros nela: L1, L2, e max.\n","\n","$$\n","X' = \\frac{X}{\\lVert X \\rVert_2}\n","$$\n","\n","**Vantagens:**\n","- Escala todas as amostras para o mesmo tamanho, útil para técnicas baseadas em distâncias\n","- Não afeta a distribuição dos dados dentro da amostra\n","\n","**Desvantagens:**\n","- Pode não ser adequado quando a magnetude das características importa\n","- Pode levar à perda de variabilidade entre amostras.\n","\n","**Casos de uso:**\n","- Clustering\n","- Algoritmos baseados em vetores e ângulos\n","- Análise de similaridade"],"metadata":{"id":"pdt2S8e7Uw6Z"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"cMFkqhBGR9RQ"},"outputs":[],"source":[]}]}