{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM5FGLx6FPzSEFYhHc97asC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Bagging\n","É uma técnica de __ensemble__ usada para melhorar a precisão e reduzir a variância dos modelos, assim como busca tentar evitar ao máximo o overfitting.\n","\n"," Seu principal objetivo é aumentar a robustez e estabilidade dos algoritmos que possuem alta variância, como as _árvores de decisão_, combinando muitas versões do mesmo modelo, mas treinados em diferentes subconjuntos de dados.\n","\n"," __Como funciona:__\n"," - Primeiramente, é criado um subconjunto de dados (__Bootstrap__). A ideia é que sejam criados diferentes subconjuntos de dados de forma aleatória. Isso envolve a seleção desses dados de forma aleatória e __com reposição__, ou seja, uma mesma amostra pode ser escolhida mais de uma vez para diferentes subconjuntos.\n"," - É realizado o treinamento de múltiplos modelos onde, para cada subconjunto criado, é treinado um modelo completamente independente dos outros.\n"," - Após o treinamento desses modelos, é realizada a __agregação__. Onde as previsões são combinadas de forma a melhorar o desempenho do modelo final. Para problemas de regressão, geralmente é utilizada a média das previsões dos modelos. Para problemas de classificação, geralmente se usa a classe mais votada pelos modelos.\n","\n","\n"," __Principais objetivos:__\n"," - Reduzir a variância;\n"," - Evitar overfitting;\n"," - Melhorar a acurácia.\n","\n","<br>\n","\n"," É importante ressaltar que a técnica de Bagging pode ser utilizada em outros algoritmos de machine learning. Alguns exemplos onde o baggins pode ser aplicado são:\n"," - Árvores de decisão individuais, sem aplicar o conceito de florestas;\n"," - KNN;\n"," - Regressão Linear;\n"," - Redes Neurais;\n"," - SVM;\n"," - Entre outros."],"metadata":{"id":"4qfYXm3XIoDv"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"R99xkHzbo80W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1729094903221,"user_tz":180,"elapsed":24757,"user":{"displayName":"Diogo Rezende","userId":"13522161648732571063"}},"outputId":"1b03a91e-e92f-44a1-81e5-f09621bd48ef"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Importação do google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# Importações\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import pickle\n","import warnings\n","warnings.filterwarnings('ignore')\n","plt.style.use('ggplot')"],"metadata":{"id":"AXVkkvvUFe4p","executionInfo":{"status":"ok","timestamp":1729094911379,"user_tz":180,"elapsed":8161,"user":{"displayName":"Diogo Rezende","userId":"13522161648732571063"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["alvo = pd.read_pickle('/content/drive/MyDrive/Udemy/ML com Python/1 - Aprendizado Supervisionado: Classificacao/heart.pkl')\n","\n","# Variáveis previsoras onde as variáveis categóricas foram transformadas em numéricas manualmente, sem escalonamento\n","previsores = pd.read_pickle('/content/drive/MyDrive/Udemy/ML com Python/1 - Aprendizado Supervisionado: Classificacao/heart2.pkl')\n","\n","# previsores_esc = pd.read_pickle('/content/drive/MyDrive/Udemy/ML com Python/1 - Aprendizado Supervisionado: Classificacao/heart3.pkl')\n","\n","# Variáveis previsoras onde as variáveis categóricas foram transformadas em numéricas pelo LabelEncoder.\n","previsores2 = pd.read_pickle('/content/drive/MyDrive/Udemy/ML com Python/1 - Aprendizado Supervisionado: Classificacao/heart4.pkl')\n","\n","# Variáveis previsoras onde as variáveis categóricas foram transformadas em numéricas pelo LabelEncoder e OneHotEncoder, sem escalonamento.\n","previsores3 = pd.read_pickle('/content/drive/MyDrive/Udemy/ML com Python/1 - Aprendizado Supervisionado: Classificacao/heart5.pkl')\n","\n","# Variáveis previsoras onde as variáveis categóricas foram transformadas pelo LabelEncoder e OHE, com escalonamento.\n","previsores3_esc = pd.read_pickle('/content/drive/MyDrive/Udemy/ML com Python/1 - Aprendizado Supervisionado: Classificacao/heart6.pkl')"],"metadata":{"id":"t4ucSIkDFm4n","executionInfo":{"status":"ok","timestamp":1729094913551,"user_tz":180,"elapsed":2174,"user":{"displayName":"Diogo Rezende","userId":"13522161648732571063"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.model_selection import cross_val_score, StratifiedKFold"],"metadata":{"id":"CjTY_GgfFn9f","executionInfo":{"status":"ok","timestamp":1729094992620,"user_tz":180,"elapsed":271,"user":{"displayName":"Diogo Rezende","userId":"13522161648732571063"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Criação do modelo\n","tree = DecisionTreeClassifier()\n","skfold = StratifiedKFold(n_splits=3)\n","resultado = cross_val_score(tree, previsores, alvo, cv=skfold)\n","print(resultado.mean())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9SbPeN2IF8jl","executionInfo":{"status":"ok","timestamp":1729095039179,"user_tz":180,"elapsed":296,"user":{"displayName":"Diogo Rezende","userId":"13522161648732571063"}},"outputId":"977283ab-f67d-43fc-c77e-d781124c8ef5"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["0.74799099967856\n"]}]},{"cell_type":"markdown","source":["Neste código acima utilizamos os valores padrão da árvore de decisão. Não realizamos nenhum ajuste ou otimização, e isso pode levar nosso modelo ao overfitting.\n","\n","Vamos mexer um pouco nos parâmetros da árvore."],"metadata":{"id":"UaBcoiZPGR2c"}},{"cell_type":"code","source":["from sklearn.model_selection import GridSearchCV"],"metadata":{"id":"TH6V-mlmG8np","executionInfo":{"status":"ok","timestamp":1729095276344,"user_tz":180,"elapsed":311,"user":{"displayName":"Diogo Rezende","userId":"13522161648732571063"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Valores a testar\n","min_splits = np.array([2, 3, 4, 5, 6, 7, 8])\n","max_depth = np.array([4, 5, 6, 7, 8, 9, 10])\n","min_leaf = np.array([1, 2, 3, 4, 5, 6, 7, 8])\n","indice = ['gini', 'entropy']\n","\n","# Criação do dicionário\n","valores_grid = dict(min_samples_split=min_splits, max_depth=max_depth, min_samples_leaf=min_leaf, criterion=indice)\n","\n","# Criar o modelo\n","tree = DecisionTreeClassifier()\n","\n","# Aplicar os grids na GridSearch\n","tree_grid = GridSearchCV(estimator=tree, param_grid=valores_grid, cv=3)\n","tree_grid.fit(previsores, alvo)\n","\n","# Melhores parametros\n","print(tree_grid.best_params_)\n","\n","# Melhores resultados\n","print(tree_grid.best_score_)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UvpvzjT4HBpz","executionInfo":{"status":"ok","timestamp":1729095541019,"user_tz":180,"elapsed":19470,"user":{"displayName":"Diogo Rezende","userId":"13522161648732571063"}},"outputId":"c95e42b1-64f8-48a1-ba7f-41758b3cf051"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["{'criterion': 'gini', 'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2}\n","0.8069038179934998\n"]}]},{"cell_type":"markdown","source":["O desempenho recebeu uma melhora importante. Porém, agora vamos aplicar a técnica de __Bagging__.\n","\n","Ao invés de realizar uma rodada com valores a serem testados, iremos construir a árvore com seus valores padrão novamente, porém iremos aplicar a técnica citada acima. Essa técnica irá criar árvores com dados diferentes."],"metadata":{"id":"Pu5ESOkgIRH0"}},{"cell_type":"code","source":["from sklearn.ensemble import BaggingClassifier"],"metadata":{"id":"2011TbiuIB5H","executionInfo":{"status":"ok","timestamp":1729095864738,"user_tz":180,"elapsed":355,"user":{"displayName":"Diogo Rezende","userId":"13522161648732571063"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Criação do modelo\n","tree2 = DecisionTreeClassifier()\n","modelo_bagging = BaggingClassifier(estimator=tree2, n_estimators=100, max_samples=.5)\n","resultado = cross_val_score(modelo_bagging, previsores, alvo, cv=skfold)\n","print(resultado.mean())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A2r7By5VJRM9","executionInfo":{"status":"ok","timestamp":1729096189266,"user_tz":180,"elapsed":1274,"user":{"displayName":"Diogo Rezende","userId":"13522161648732571063"}},"outputId":"094b4f13-c4d8-4df7-ab3b-8690488ee3d4"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["0.8352512589735347\n"]}]},{"cell_type":"markdown","source":["É importante ressaltar que diferente do que fizemos anteriormente, onde fizemos o ajuste dos parâmetros e exibimos os melhores parâmetros entrados, dessa vez utilizamos a árvore com seus valores padrão mas aplicamos a técnica de bagging, onde são criadas diversas árvores (100, no nosso caso) com dados diferentes para cada uma delas. Isso permite que o modelo aprenda diferentes padrões e seja mais generalizável."],"metadata":{"id":"X9eGGs2eK19u"}}]}